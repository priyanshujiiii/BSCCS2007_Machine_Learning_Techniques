![image](https://user-images.githubusercontent.com/89120960/232202739-27c55597-bfba-4c67-b9b2-7cb21950b440.png)


<p>
  Large margin classifiers are capable of generalizing better to unseen data.

When a linear classifier is trained on linearly separable data, there are potentially many hyperplanes that can separate the data correctly. However, hyperplanes with larger margins are preferred because they have better generalization properties. This is because a hyperplane with a large margin is more likely to correctly classify future, unseen data points since it is farther away from the training data points. In contrast, a hyperplane with a small margin is more likely to misclassify future, unseen data points since it is closer to the training data points and is more sensitive to small changes in the data.

Furthermore, large margin classifiers have better resistance to noise and outliers, as they are less likely to be influenced by individual data points that are far away from the decision boundary.

Therefore, in the case of linearly separable data, a large margin classifier is preferred because it has better generalization properties and is more robust to noise and outliers.
</p>
