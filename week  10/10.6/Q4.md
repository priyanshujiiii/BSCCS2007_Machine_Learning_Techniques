![image](https://user-images.githubusercontent.com/89120960/232238578-327d9e7e-010d-4da8-b1c9-81f425c22cc6.png)

<p>
If we use a soft-margin SVM for data that is linearly separable, the soft-margin formulation turns into a hard-margin one when C approaches infinity (i.e., C → ∞). As C increases, the SVM becomes more tolerant of errors, but as C approaches infinity, the SVM becomes less tolerant of errors and tries to classify all training examples correctly, which is the goal of a hard-margin SVM.
</p>
