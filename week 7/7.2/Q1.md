![image](https://user-images.githubusercontent.com/89120960/234195065-43717c20-86c9-498c-95ff-15743be6f0ae.png)


In k-nearest neighbors (k-NN) algorithm, the predicted label for a test-point is determined by the majority label of its k nearest neighbors in the training data. Based on the given distances of the test-point from all the training data-points and their corresponding labels, we can determine the k nearest neighbors and their labels. Let's calculate it step by step:

Given:
- Test-point: x_test = [10, 5, 4, 9, 3, 2]
- Labels of training data-points: y_i = [1, -1, 1, -1, 1, -1]
- Distances of test-point from training data-points: d(x_test, x_i) = [10, 5, 4, 9, 3, 2]

We need to find the 3 nearest neighbors to the test-point based on the distances.

Step 1: Sort the distances in ascending order:
d(x_test, x_i) = [2, 3, 4, 5, 9, 10]

Step 2: Select the k nearest neighbors:
k = 3, so we select the first 3 distances from the sorted list:
d(x_test, x_i) = [2, 3, 4]

Step 3: Determine the corresponding labels of the k nearest neighbors:
y_i = [1, -1, 1] (based on the indices corresponding to the selected distances)

Step 4: Predict the label for the test-point:
The majority label among the k nearest neighbors is 1, since there are 2 positive labels and 1 negative label. Therefore, the predicted label for the test-point is 1.
